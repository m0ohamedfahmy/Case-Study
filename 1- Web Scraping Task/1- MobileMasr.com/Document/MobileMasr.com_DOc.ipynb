{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59627c81",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align: center; background-color: #569db3; color: white; padding: 14px; line-height: 1;border-radius:20px\">Document ‚Äî Web Scraping [MobileMasr.com]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2674d975",
   "metadata": {},
   "source": [
    "## üß≠ Table of Contents\n",
    "1. [‚öôÔ∏è Code Approaches](#Ô∏ècode)\n",
    "2. [üåê Which Website Was Scraped](#-which-website-was-scraped)\n",
    "3. [üíæ Data Collected](#-data-collected)\n",
    "4. [üöß Challenges and Solutions](#-challenges-and-solutions)\n",
    "5. [üìò How to Run the Script](#-how-to-run-the-script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fc41f",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red; font-weight:bold; background-color:#f5f5f5; border:2px solid red; padding:10px; border-radius:10px; font-family:monospace;\">\n",
    "<code>1- Code approaches:-</code>\n",
    "</h1>\n",
    "\n",
    "In this notebook, I demonstrate **two different approaches** to writing Python web scraping code:\n",
    "\n",
    "**<span style=\"color:blue;\">1. Monolithic Approach (All-in-One Code)</span>**\n",
    "\n",
    "   - In this approach, the entire scraping process is written in one continuous block of code.  \n",
    "   - It includes fetching pages, parsing HTML, extracting product details, and writing to CSV all together.  \n",
    "   - This method is simple for small scripts but can become hard to maintain and read for larger projects.\n",
    "\n",
    "**<span style=\"color:blue;\">2. Modular Approach (Using Functions)</span>**\n",
    "   - In this approach, the code is divided into **functions** for each specific task, such as:\n",
    "     - Creating the CSV file\n",
    "     - Fetching a webpage\n",
    "     - Parsing a product card\n",
    "     - Writing data to CSV\n",
    "     - Main loop controlling the scraping\n",
    "   - This method improves **readability, reusability, and maintainability**.\n",
    "   - Each function has a clear responsibility, making the code easier to debug and extend.\n",
    "\n",
    "Both methods achieve the same end result: scraping mobile phone data from the website and saving it to a CSV file.  \n",
    "The difference lies in **code organization and readability**.\n",
    "\n",
    "\n",
    "<h1 style=\"color:red; font-weight:bold; background-color:#f5f5f5; border:2px solid red; padding:10px; border-radius:10px; font-family:monospace;\">\n",
    "<code>2- Which Website Was Scraped :- </code>\n",
    "</h1>\n",
    "\n",
    "- **Website:** [MobileMasr.com](https://mobilemasr.com)  \n",
    "- **Category:** Mobile Phones  \n",
    "- The script navigates through **all pages** of the mobile phone category.\n",
    "\n",
    "<h1 style=\"color:red; font-weight:bold; background-color:#f5f5f5; border:2px solid red; padding:10px; border-radius:10px; font-family:monospace;\">\n",
    "<code>3- Data Collected </code>\n",
    "</h1>\n",
    "\n",
    "Each row in the CSV file contains the following columns:\n",
    "\n",
    "- **`product_name:`** Name of the mobile phone  \n",
    "- **`price:`** Price of the mobile phone  \n",
    "- **`seller:`** Seller name  \n",
    "- **`status:`** Condition of the product (`new` / `used`)  \n",
    "- **`battery_condition:`** Battery condition (if listed)  \n",
    "- **`warranty_period:`** Warranty period (if listed)  \n",
    "- **`memory_size:`** The storage size (e.g., 128 GB).   \n",
    "- **`RAM_size:`** The RAM capacity of the phone (e.g., 4 GB \n",
    "- **`color:`** Phone color  \n",
    "- **`page_number:`** Page number where the product was scraped  \n",
    "- **`product_url:`** URL of the product page\n",
    "\n",
    "\n",
    "<h1 style=\"color:red; font-weight:bold; background-color:#f5f5f5; border:2px solid red; padding:10px; border-radius:10px; font-family:monospace;\">\n",
    "<code>4- Some Challenges and Solutions :-</code>\n",
    "</h1>\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:blue;\"><code>Challenge 1:</code> Dynamic Class Names in HTML</span>\n",
    "\n",
    "\n",
    "\n",
    "**Problem:**  \n",
    "Most of the website‚Äôs elements (like `<div>` and `<a>` tags) used **Bootstrap or dynamically generated class names**.  \n",
    "This caused issues because when the website was updated, class names often changed ‚Äî which meant the scraper couldn‚Äôt find the elements anymore, and no data was returned.\n",
    "\n",
    "**Solution:**  \n",
    "To make the scraper more stable and update-proof:\n",
    "- I made the code depend on **static or consistent class names** whenever possible.  \n",
    "- When all class names were dynamic, I used **CSS selectors with partial matches** (e.g., selecting a part of the class name that was unlikely to change).  \n",
    "- This allowed the scraper to locate elements reliably even if the site structure changed slightly.\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:blue;\"><code>Challenge 2:</code>Handling Request Failures</span>\n",
    "\n",
    "**Problem:** Some requests failed due to network issues or missing pages.  \n",
    "**Solution:** Wrapped each `requests.get()` call inside a `try-except` block to catch exceptions and continue scraping without stopping the program.\n",
    "\n",
    "### <span style=\"color:blue;\"><code>Challenge 3:</code> Missing Data in Some Products</span>\n",
    "\n",
    "**Problem:** Some product pages had missing fields like seller or warranty.  \n",
    "**Solution:** Added conditional checks (`if ... else 'N/A'`) before writing data to the CSV to prevent errors and keep the dataset consistent.\n",
    "\n",
    "\n",
    "### <span style=\"color:blue;\"><code>Challenge 4:</code> Extracting Battery and Warranty Information</span>\n",
    "\n",
    "\n",
    "**Problem:**  \n",
    "On the main product page, both **battery condition** and **warranty period** were displayed inside similar `<span>` tags within the same parent container (`div.product-card`).  \n",
    "There was no unique class or identifier to tell which one was which.  \n",
    "Additionally, in some products, **one of the values was missing**, which made it even harder to identify which existing value belonged to the battery or the warranty.\n",
    "\n",
    "**Solution:**  \n",
    "To handle this issue:\n",
    "- I analyzed the text inside each `<span>` to detect patterns.  \n",
    "- If the text contained **letters or symbols like `%`**, it was identified as **battery condition** (e.g., ‚ÄúBattery 95%‚Äù, very good).   \n",
    "- When a value was missing, I safely assigned **\"N/A\"** to that field so the script wouldn‚Äôt crash and the data structure stayed consistent.\n",
    "\n",
    "This logic ensured that even if one of the fields was absent, the scraper still recorded the correct information in the right column.\n",
    "\n",
    "\n",
    "### <span style=\"color:blue;\"><code>Challenge 5:</code> Extracting and Cleaning Product Names</span>\n",
    "\n",
    "\n",
    "**Problem:**  \n",
    "The product name (`<h1>` tag) on the details page often included **extra technical details** such as memory size or RAM (e.g., \"iPhone 11 128 ÿ¨Ÿäÿ¨ÿßÿ®ÿßŸäÿ™ ÿ±ÿßŸÖÿßÿ™ 4\").  \n",
    "This made the product name inconsistent and hard to analyze later because those details were already extracted separately in other fields.  \n",
    "Additionally, in some cases, the `<h1>` tag itself was missing, which could cause the scraper to throw an error.\n",
    "\n",
    "**Solution:**  \n",
    "To solve this:\n",
    "- I used a **regular expression with `re.split()`** to split the text at patterns like `\"ÿ±ÿßŸÖÿßÿ™\"` or `\"ÿ¨Ÿäÿ¨ÿßÿ®ÿßŸäÿ™\"`, keeping only the clean product name before these words. \n",
    "\n",
    "```python\n",
    " - re.split(r'\\s+(?:ÿ±ÿßŸÖÿßÿ™|ÿ¨Ÿäÿ¨ÿßÿ®ÿßŸäÿ™)\\s+', text)[0].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2b755",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red; font-weight:bold; background-color:#f5f5f5; border:2px solid red; padding:10px; border-radius:10px; font-family:monospace;\">\n",
    "<code>üìò 5- How to Run the Script and What Sites Were Scraped </code>\n",
    "</h1>\n",
    "\n",
    "## 1. Overview\n",
    "This script scrapes **mobile phone data** from the website [MobileMasr.com](https://mobilemasr.com), specifically from the **Mobile Phones** category.  \n",
    "It extracts detailed information about each phone (price, seller, condition, specifications, etc.) and saves the data into a CSV file.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How to Run the Script\n",
    "\n",
    "1. **Install required libraries:**\n",
    "   ```bash\n",
    "   pip install requests beautifulsoup4\n",
    "\n",
    "## üß† How the Script Works\n",
    "\n",
    "Run the script in your Python environment or notebook cell.  \n",
    "The script will:\n",
    "\n",
    "- Start from **page 1** of the ‚ÄúMobile Phones‚Äù category.  \n",
    "- Visit each product page to extract detailed information.  \n",
    "- Continue automatically to the next page until no more products are available.  \n",
    "\n",
    "### üóÇÔ∏è Output\n",
    "- A CSV file named **`mobile_misr_phones_1.csv`** will be created in your working directory.  \n",
    "- Each row represents one mobile phone with its full details.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
